{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8440b0-526a-4296-a094-734d48e030e0",
   "metadata": {},
   "source": [
    "<img src=\"udea.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c44a8dc-8320-4849-95a0-095cc719790f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h1>ANALÍTICA DE DATOS Y MACHINE LEARNING APLICADO A LAS CIENCIAS POLÍTICAS</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9a3ae",
   "metadata": {},
   "source": [
    "# Scikit-Learn Cheatsheet para el Proyecto Titanic\n",
    "\n",
    "Una guía rápida de referencia con todos los códigos de scikit-learn necesarios para el proyecto de clasificación del Titanic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a166e",
   "metadata": {},
   "source": [
    "## Imports Básicos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f94957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS BÁSICOS DE SCIKIT-LEARN\n",
    "# ============================================================================\n",
    "\n",
    "# train_test_split: Función para dividir el dataset en conjuntos de \n",
    "# entrenamiento y prueba. Esencial para evaluar el modelo correctamente.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelos de clasificación disponibles en scikit-learn:\n",
    "# - LogisticRegression: Modelo de regresión logística para clasificación binaria\n",
    "# - RandomForestClassifier: Modelo de ensamble basado en múltiples árboles de decisión\n",
    "# - SVC: Support Vector Classifier, modelo basado en máquinas de vectores de soporte\n",
    "# - DecisionTreeClassifier: Clasificador basado en un único árbol de decisión\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Métricas de evaluación para medir el desempeño del modelo:\n",
    "# - accuracy_score: Calcula el porcentaje de predicciones correctas\n",
    "# - precision_score: Calcula la precisión (predicciones positivas correctas)\n",
    "# - recall_score: Calcula la sensibilidad (casos positivos identificados)\n",
    "# - f1_score: Calcula el F1-score (balance entre precisión y recall)\n",
    "# - confusion_matrix: Genera la matriz de confusión\n",
    "# - classification_report: Genera un reporte completo con todas las métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Herramientas de preprocesamiento (opcional, para proyectos avanzados):\n",
    "# - StandardScaler: Estandariza los datos (media=0, desviación estándar=1)\n",
    "# - LabelEncoder: Convierte etiquetas categóricas a numéricas\n",
    "# - SimpleImputer: Rellena valores faltantes con estrategias como media, mediana, etc.\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bc280",
   "metadata": {},
   "source": [
    "## 1. División de Datos (Train/Test Split)\n",
    "\n",
    "### Función: `train_test_split()`\n",
    "\n",
    "**Propósito**: Divide el dataset en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "**Parámetros importantes**:\n",
    "- `X`: Características (features)\n",
    "- `y`: Variable objetivo (target)\n",
    "- `test_size`: Tamaño del conjunto de prueba (0.0 a 1.0)\n",
    "- `random_state`: Semilla aleatoria para reproducibilidad\n",
    "- `stratify`: Mantiene la distribución de clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719dc63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# División básica (80% entrenamiento, 20% prueba)\u001b[39;00m\n\u001b[32m      4\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mX\u001b[49m, y, \n\u001b[32m      6\u001b[39m     test_size=\u001b[32m0.2\u001b[39m,        \u001b[38;5;66;03m# Porcentaje para prueba (0.2 = 20%)\u001b[39;00m\n\u001b[32m      7\u001b[39m     random_state=\u001b[32m42\u001b[39m       \u001b[38;5;66;03m# Semilla para reproducibilidad\u001b[39;00m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Con más opciones\u001b[39;00m\n\u001b[32m     11\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m     12\u001b[39m     X, y,\n\u001b[32m     13\u001b[39m     test_size=\u001b[32m0.2\u001b[39m,\n\u001b[32m     14\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     15\u001b[39m     stratify=y            \u001b[38;5;66;03m# Mantiene proporción de clases en ambos conjuntos\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================================\n",
    "# DIVISIÓN BÁSICA DE DATOS\n",
    "# ============================================================================\n",
    "# train_test_split divide el dataset en dos partes:\n",
    "# - X_train, y_train: Datos para entrenar el modelo (80% por defecto)\n",
    "# - X_test, y_test: Datos para evaluar el modelo (20% por defecto)\n",
    "# \n",
    "# Parámetros:\n",
    "# - X: Matriz de características (features) del dataset\n",
    "# - y: Vector de etiquetas objetivo (lo que queremos predecir)\n",
    "# - test_size=0.2: Especifica que el 20% de los datos será para prueba\n",
    "# - random_state=42: Semilla aleatoria para garantizar resultados reproducibles\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,        # 20% de los datos para prueba, 80% para entrenamiento\n",
    "    random_state=42       # Semilla para reproducibilidad (mismo resultado cada vez)\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# DIVISIÓN CON ESTRATIFICACIÓN (RECOMENDADO)\n",
    "# ============================================================================\n",
    "# La opción stratify=y mantiene la misma proporción de clases en ambos conjuntos\n",
    "# Esto es importante cuando hay desbalance de clases (ej: 70% no sobrevivieron, 30% sí)\n",
    "# Sin stratify, podría pasar que el conjunto de prueba tenga una proporción diferente\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,        # 20% para prueba\n",
    "    random_state=42,      # Semilla para reproducibilidad\n",
    "    stratify=y            # Mantiene la misma proporción de clases en train y test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13549b4",
   "metadata": {},
   "source": [
    "## 2. Modelos de Clasificación\n",
    "\n",
    "### 2.1 Regresión Logística\n",
    "\n",
    "**Parámetros comunes**:\n",
    "- `max_iter`: Número máximo de iteraciones (default: 100)\n",
    "- `random_state`: Semilla aleatoria\n",
    "- `C`: Parámetro de regularización (default: 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20826a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ============================================================================\n",
    "# CREACIÓN DEL MODELO DE REGRESIÓN LOGÍSTICA\n",
    "# ============================================================================\n",
    "# LogisticRegression es un modelo lineal que estima probabilidades usando \n",
    "# la función logística. Es ideal para clasificación binaria.\n",
    "# \n",
    "# max_iter=200: Aumenta el número máximo de iteraciones del algoritmo de \n",
    "# optimización (por defecto es 100, pero a veces necesita más)\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# ============================================================================\n",
    "# ENTRENAMIENTO DEL MODELO\n",
    "# ============================================================================\n",
    "# El método fit() entrena el modelo con los datos de entrenamiento.\n",
    "# Durante el entrenamiento, el modelo aprende los patrones y relaciones\n",
    "# entre las características (X_train) y las etiquetas (y_train).\n",
    "# \n",
    "# IMPORTANTE: Solo se usa X_train y y_train, nunca los datos de prueba\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICCIONES DEL MODELO\n",
    "# ============================================================================\n",
    "# El método predict() genera predicciones de clase (0 o 1) para cada muestra\n",
    "# en X_test. Retorna un array con las clases predichas.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ============================================================================\n",
    "# PROBABILIDADES DE PREDICCIÓN\n",
    "# ============================================================================\n",
    "# El método predict_proba() retorna las probabilidades de cada clase.\n",
    "# Útil para análisis más detallados o cuando necesitas el nivel de confianza\n",
    "# del modelo en sus predicciones.\n",
    "# Retorna un array de forma (n_samples, n_classes) con probabilidades\n",
    "y_pred_proba = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa80e9",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35007572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ============================================================================\n",
    "# CREACIÓN DEL MODELO RANDOM FOREST\n",
    "# ============================================================================\n",
    "# RandomForestClassifier es un modelo de ensamble que combina múltiples\n",
    "# árboles de decisión. Cada árbol vota y la clase más votada gana.\n",
    "# \n",
    "# Parámetros:\n",
    "# - n_estimators=100: Número de árboles de decisión en el bosque\n",
    "#   (más árboles = mejor rendimiento pero más lento)\n",
    "# - random_state=42: Semilla para reproducibilidad\n",
    "# - max_depth=10: Profundidad máxima de cada árbol (evita sobreajuste)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,     # Número de árboles en el bosque\n",
    "    random_state=42,      # Semilla para reproducibilidad\n",
    "    max_depth=10          # Profundidad máxima de cada árbol\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece74d5",
   "metadata": {},
   "source": [
    "### 2.3 Support Vector Machine (SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# ============================================================================\n",
    "# CREACIÓN DEL MODELO SUPPORT VECTOR MACHINE (SVM)\n",
    "# ============================================================================\n",
    "# SVC (Support Vector Classifier) encuentra el hiperplano óptimo que separa\n",
    "# las clases maximizando el margen entre ellas.\n",
    "# \n",
    "# Parámetros:\n",
    "# - kernel='rbf': Tipo de kernel (Radial Basis Function)\n",
    "#   Otros kernels: 'linear', 'poly', 'sigmoid'\n",
    "# - random_state=42: Semilla para reproducibilidad\n",
    "model = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355a370",
   "metadata": {},
   "source": [
    "### 2.4 Árbol de Decisión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ============================================================================\n",
    "# CREACIÓN DEL MODELO ÁRBOL DE DECISIÓN\n",
    "# ============================================================================\n",
    "# DecisionTreeClassifier crea un árbol de decisión que divide los datos\n",
    "# basándose en reglas simples (if-else) hasta llegar a una predicción.\n",
    "# \n",
    "# Parámetros:\n",
    "# - max_depth=5: Profundidad máxima del árbol\n",
    "#   (limitar la profundidad previene sobreajuste)\n",
    "# - random_state=42: Semilla para reproducibilidad\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30702f4e",
   "metadata": {},
   "source": [
    "## 3. Métricas de Evaluación\n",
    "\n",
    "### 3.1 Accuracy (Precisión)\n",
    "\n",
    "**Qué mide**: Porcentaje total de predicciones correctas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ============================================================================\n",
    "# CÁLCULO DE ACCURACY (PRECISIÓN)\n",
    "# ============================================================================\n",
    "# Accuracy mide el porcentaje total de predicciones correctas.\n",
    "# Fórmula: (Verdaderos Positivos + Verdaderos Negativos) / Total\n",
    "# \n",
    "# Parámetros:\n",
    "# - y_test: Valores reales (ground truth) del conjunto de prueba\n",
    "# - y_pred: Valores predichos por el modelo\n",
    "# \n",
    "# Retorna: Un valor entre 0 y 1 (o entre 0% y 100%)\n",
    "# Ejemplo: 0.81 significa que el 81% de las predicciones fueron correctas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar el resultado formateado\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7814ee",
   "metadata": {},
   "source": [
    "### 3.2 Precision (Precisión)\n",
    "\n",
    "**Qué mide**: De las predicciones positivas, cuántas son realmente correctas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa095bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# ============================================================================\n",
    "# CÁLCULO DE PRECISION\n",
    "# ============================================================================\n",
    "# Precision mide: De todas las predicciones positivas que hizo el modelo,\n",
    "# ¿cuántas eran realmente positivas?\n",
    "# Fórmula: Verdaderos Positivos / (Verdaderos Positivos + Falsos Positivos)\n",
    "# \n",
    "# Es útil cuando los falsos positivos son costosos.\n",
    "# Ejemplo: Si el modelo predice \"sobrevivió\" 100 veces, y 80 realmente \n",
    "# sobrevivieron, la precision es 0.80 (80%)\n",
    "# \n",
    "# Parámetros:\n",
    "# - y_test: Valores reales del conjunto de prueba\n",
    "# - y_pred: Valores predichos por el modelo\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"Precision: {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f86af",
   "metadata": {},
   "source": [
    "### 3.3 Recall (Sensibilidad)\n",
    "\n",
    "**Qué mide**: De los casos reales positivos, cuántos identificó el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae525fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# ============================================================================\n",
    "# CÁLCULO DE RECALL (SENSIBILIDAD)\n",
    "# ============================================================================\n",
    "# Recall mide: De todos los casos que realmente son positivos,\n",
    "# ¿cuántos identificó correctamente el modelo?\n",
    "# Fórmula: Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)\n",
    "# \n",
    "# También se conoce como \"Sensibilidad\" o \"True Positive Rate\"\n",
    "# Es útil cuando los falsos negativos son costosos.\n",
    "# Ejemplo: Si 100 personas realmente sobrevivieron, y el modelo identificó\n",
    "# 75 de ellas, el recall es 0.75 (75%)\n",
    "# \n",
    "# Parámetros:\n",
    "# - y_test: Valores reales del conjunto de prueba\n",
    "# - y_pred: Valores predichos por el modelo\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd9c0e",
   "metadata": {},
   "source": [
    "### 3.4 F1-Score\n",
    "\n",
    "**Qué mide**: Balance entre Precision y Recall (media armónica).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ============================================================================\n",
    "# CÁLCULO DE F1-SCORE\n",
    "# ============================================================================\n",
    "# F1-Score es la media armónica entre Precision y Recall.\n",
    "# Fórmula: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "# \n",
    "# Es útil cuando necesitas un balance entre Precision y Recall.\n",
    "# El F1-Score es especialmente importante cuando hay desbalance de clases.\n",
    "# Valores más altos indican mejor balance entre ambas métricas.\n",
    "# \n",
    "# Parámetros:\n",
    "# - y_test: Valores reales del conjunto de prueba\n",
    "# - y_pred: Valores predichos por el modelo\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dec24e",
   "metadata": {},
   "source": [
    "### 3.5 Matriz de Confusión\n",
    "\n",
    "**Interpretación**:\n",
    "- `cm[0,0]`: Verdaderos Negativos (TN)\n",
    "- `cm[0,1]`: Falsos Positivos (FP)\n",
    "- `cm[1,0]`: Falsos Negativos (FN)\n",
    "- `cm[1,1]`: Verdaderos Positivos (TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ============================================================================\n",
    "# MATRIZ DE CONFUSIÓN\n",
    "# ============================================================================\n",
    "# La matriz de confusión muestra todos los tipos de predicciones:\n",
    "# - Verdaderos Negativos (TN): Predijo negativo y era negativo\n",
    "# - Falsos Positivos (FP): Predijo positivo pero era negativo\n",
    "# - Falsos Negativos (FN): Predijo negativo pero era positivo\n",
    "# - Verdaderos Positivos (TP): Predijo positivo y era positivo\n",
    "# \n",
    "# Estructura de la matriz:\n",
    "#                 Predicción\n",
    "#              Negativo  Positivo\n",
    "# Real Negativo   TN       FP\n",
    "# Real Positivo   FN       TP\n",
    "# \n",
    "# Parámetros:\n",
    "# - y_test: Valores reales del conjunto de prueba\n",
    "# - y_pred: Valores predichos por el modelo\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Mostrar la matriz en formato array\n",
    "print(\"Matriz de confusión (formato array):\")\n",
    "print(cm)\n",
    "\n",
    "# ============================================================================\n",
    "# FORMATO MÁS LEGIBLE DE LA MATRIZ DE CONFUSIÓN\n",
    "# ============================================================================\n",
    "# Mostrar la matriz con etiquetas para mejor interpretación\n",
    "print(\"\\n                    Predicción\")\n",
    "print(\"                 No Sobrevivió  Sobrevivió\")\n",
    "print(f\"Real No Sobrevivió      {cm[0,0]:4d}        {cm[0,1]:4d}\")\n",
    "print(f\"Real Sobrevivió         {cm[1,0]:4d}        {cm[1,1]:4d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6586e4",
   "metadata": {},
   "source": [
    "### 3.6 Classification Report (Reporte Completo)\n",
    "\n",
    "**Muestra**: Precision, Recall, F1-Score para cada clase y promedios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33920e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ============================================================================\n",
    "# CLASSIFICATION REPORT (REPORTE COMPLETO)\n",
    "# ============================================================================\n",
    "# classification_report genera un reporte con todas las métricas principales\n",
    "# para cada clase y promedios:\n",
    "# - Precision para cada clase\n",
    "# - Recall para cada clase\n",
    "# - F1-Score para cada clase\n",
    "# - Support: Número de muestras de cada clase\n",
    "# - Promedios (macro avg, weighted avg)\n",
    "# \n",
    "# Es muy útil para tener una visión completa del desempeño del modelo\n",
    "# en un solo lugar.\n",
    "# \n",
    "# Parámetros:\n",
    "# - y_test: Valores reales del conjunto de prueba\n",
    "# - y_pred: Valores predichos por el modelo\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Mostrar el reporte completo\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabbc89",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento (Opcional - Avanzado)\n",
    "\n",
    "### 4.1 Estandarización de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ============================================================================\n",
    "# ESTANDARIZACIÓN DE DATOS\n",
    "# ============================================================================\n",
    "# StandardScaler transforma los datos para que tengan media=0 y desviación=1\n",
    "# Esto es importante para modelos sensibles a la escala (SVM, regresión logística)\n",
    "# \n",
    "# Proceso:\n",
    "# 1. fit_transform() en X_train: Calcula la media y desviación de entrenamiento\n",
    "#    y aplica la transformación\n",
    "# 2. transform() en X_test: Aplica la misma transformación usando los parámetros\n",
    "#    calculados en el entrenamiento\n",
    "# \n",
    "# IMPORTANTE: Nunca uses fit() o fit_transform() en X_test, solo transform()\n",
    "# Esto evita \"data leakage\" (filtrado de información del conjunto de prueba)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Calcular parámetros (media, desviación) y transformar datos de entrenamiento\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicar la misma transformación a los datos de prueba (sin recalcular parámetros)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0378c",
   "metadata": {},
   "source": [
    "### 4.2 Imputación de Valores Faltantes\n",
    "\n",
    "**Estrategias**: `'mean'`, `'median'`, `'most_frequent'`, `'constant'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cfeab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ============================================================================\n",
    "# IMPUTACIÓN DE VALORES FALTANTES\n",
    "# ============================================================================\n",
    "# SimpleImputer rellena valores faltantes (NaN) usando una estrategia específica.\n",
    "# \n",
    "# Estrategias disponibles:\n",
    "# - 'mean': Rellena con la media de la columna\n",
    "# - 'median': Rellena con la mediana de la columna (recomendado para datos con outliers)\n",
    "# - 'most_frequent': Rellena con el valor más frecuente\n",
    "# - 'constant': Rellena con un valor constante especificado\n",
    "# \n",
    "# Proceso:\n",
    "# 1. fit_transform() en X_train: Calcula el valor de imputación (ej: mediana)\n",
    "#    y rellena los valores faltantes\n",
    "# 2. transform() en X_test: Rellena usando el mismo valor calculado en entrenamiento\n",
    "# \n",
    "# IMPORTANTE: Usa la misma estrategia en train y test para mantener consistencia\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Calcular valor de imputación (mediana) y rellenar datos de entrenamiento\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "# Rellenar datos de prueba usando la misma mediana calculada en entrenamiento\n",
    "X_test_imputed = imputer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516e601",
   "metadata": {},
   "source": [
    "### 4.3 Codificación de Etiquetas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cd54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================================================================\n",
    "# CODIFICACIÓN DE ETIQUETAS CATEGÓRICAS\n",
    "# ============================================================================\n",
    "# LabelEncoder convierte etiquetas categóricas (texto) a números.\n",
    "# Útil cuando tienes variables objetivo o características en formato texto.\n",
    "# \n",
    "# Ejemplo:\n",
    "# - Antes: ['male', 'female', 'male', 'female']\n",
    "# - Después: [0, 1, 0, 1]\n",
    "# \n",
    "# Proceso:\n",
    "# 1. fit(): Aprende el mapeo entre categorías y números\n",
    "# 2. transform(): Aplica el mapeo a los datos\n",
    "# 3. fit_transform(): Hace ambos pasos a la vez\n",
    "# \n",
    "# NOTA: Para características (X), es mejor usar OneHotEncoder o get_dummies()\n",
    "# de pandas. LabelEncoder es más común para la variable objetivo (y).\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Aprender el mapeo y transformar las etiquetas categóricas a números\n",
    "y_encoded = encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb29031",
   "metadata": {},
   "source": [
    "## 5. Métodos Comunes de Modelos\n",
    "\n",
    "Todos los modelos de scikit-learn comparten estos métodos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MÉTODOS COMUNES DE TODOS LOS MODELOS DE SCIKIT-LEARN\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# fit(): Entrenar el modelo\n",
    "# ----------------------------------------------------------------------------\n",
    "# Ajusta el modelo a los datos de entrenamiento.\n",
    "# Durante este proceso, el modelo aprende los patrones y relaciones\n",
    "# entre las características (X_train) y las etiquetas (y_train).\n",
    "# \n",
    "# IMPORTANTE: Solo se usa con datos de entrenamiento, nunca con datos de prueba\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# predict(): Hacer predicciones de clase\n",
    "# ----------------------------------------------------------------------------\n",
    "# Genera predicciones de clase (0 o 1 para clasificación binaria) para\n",
    "# cada muestra en X_test. Retorna un array con las clases predichas.\n",
    "# \n",
    "# Ejemplo: [0, 1, 0, 1, 0] significa que predice: no sobrevivió, sobrevivió, etc.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# predict_proba(): Obtener probabilidades (solo modelos de clasificación)\n",
    "# ----------------------------------------------------------------------------\n",
    "# Retorna las probabilidades de cada clase para cada muestra.\n",
    "# Útil para análisis de confianza o cuando necesitas umbrales personalizados.\n",
    "# \n",
    "# Retorna un array de forma (n_samples, n_classes)\n",
    "# Ejemplo: [[0.8, 0.2], [0.3, 0.7]] significa:\n",
    "#   - Primera muestra: 80% probabilidad clase 0, 20% clase 1\n",
    "#   - Segunda muestra: 30% probabilidad clase 0, 70% clase 1\n",
    "y_proba = model.predict_proba(X_test)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Atributos específicos de algunos modelos\n",
    "# ----------------------------------------------------------------------------\n",
    "# coef_: Coeficientes del modelo (solo modelos lineales como LogisticRegression)\n",
    "# Muestra la importancia/contribución de cada característica\n",
    "coefficients = model.coef_  # Disponible en LogisticRegression\n",
    "\n",
    "# feature_importances_: Importancia de características (solo modelos basados en árboles)\n",
    "# Muestra qué características son más importantes para las predicciones\n",
    "feature_importance = model.feature_importances_  # Disponible en RandomForest, DecisionTree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc1548",
   "metadata": {},
   "source": [
    "## Tips y Mejores Prácticas\n",
    "\n",
    "1. **Siempre usa `random_state`** para reproducibilidad\n",
    "2. **Nunca uses `fit()` en datos de prueba** - solo `transform()` o `predict()`\n",
    "3. **Evalúa siempre en datos de prueba**, no en datos de entrenamiento\n",
    "4. **Usa múltiples métricas** - no solo accuracy\n",
    "5. **Mantén la proporción de clases** con `stratify=y` en `train_test_split`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05472f",
   "metadata": {},
   "source": [
    "## Referencias Rápidas\n",
    "\n",
    "### Orden de Operaciones:\n",
    "1. Cargar datos → 2. Explorar → 3. Preprocesar → 4. Dividir → 5. Entrenar → 6. Predecir → 7. Evaluar\n",
    "\n",
    "### Métricas en Resumen:\n",
    "- **Accuracy**: ¿Qué tan bien predice en general?\n",
    "- **Precision**: ¿Las predicciones positivas son correctas?\n",
    "- **Recall**: ¿Encuentra todos los casos positivos?\n",
    "- **F1-Score**: Balance entre Precision y Recall\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
